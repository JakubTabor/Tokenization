# Tokenization
Here I gonna make some operations on text and test posibilities of my NLP model
# First I impoer "spacy" and load "small madel in english" then i put text into my nlp object and make for loop on my text "printing sentences" 
# It figure out that dot after Mr. it's not the end of phrase
# Then i make same for loop buy for every word in my text, Now I gonna do this same with "nltk"
# So first i import nltk and download my object, then I ipmort "sent_tokenize" and put my text into it
